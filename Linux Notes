https://swcarpentry.github.io/shell-novice/05-loop.html

So far, when specifying directory names, or even a directory path , we have been using relative paths.
When you use a relative path with a command like ls or cd, it tries to find that location from where we are, rather than from the root of the file system.
However, it is possible to specify the absolute path to a directory by including its entire path from the root directory, which is indicated by a leading slash.
The leading / tells the computer to follow the path from the root of the file system, so it always refers to exactly one directory, no matter where we are when we run the command.

For example: To find the absolute path we’re looking for, we can use pwd and then extract the piece we need to move to shell-lesson-data.
pwd = /Users/nelle/Desktop/shell-lesson-data/exercise-data
you can cd in = /Users/nelle/Desktop/shell-lesson-data
Then: Run pwd and ls -F to ensure that we’re in the directory we expect.

The shell interprets a tilde (~) character at the start of a path to mean “the current user’s home directory”.
For example, if Nelle’s home directory is /Users/nelle, then ~/data is equivalent to /Users/nelle/data. 
This only works if it is the first character in the path; here/there/~/elsewhere is not here/there/Users/nelle/elsewhere.

Another shortcut is the - (dash) character. cd will translate - into the previous directory I was in, which is faster than having to remember, then type, the full path. 
This is a very efficient way of moving back and forth between two directories – i.e. if you execute cd - twice, you end up back in the starting directory.
The difference between cd .. and cd - is that the former brings you up, while the latter brings you back.

Note that mkdir is not limited to creating single directories one at a time.
The -p option allows mkdir to create a directory with nested subdirectories in a single operation:
For example: $ mkdir -p ../project/data ../project/results
If you need to refer to names of files or directories that have spaces or other special characters, you should surround the name in single quotes ('').

It is often good practice to use all lowercase letters in names of files and directories; 
Windows and macOS file systems are typically case insensitive and therefore unable to distinguish between thesis and Thesis in the same directory.

The touch command generates a new file called my_file.txt in your current directory. You can observe this newly generated file by typing ls at the command line prompt. my_file.txt can also be viewed in your GUI file explorer.

When you inspect the file with ls -l, note that the size of my_file.txt is 0 bytes. In other words, it contains no data. If you open my_file.txt using your text editor it is blank.

Some programs do not generate output files themselves, but instead require that empty files have already been generated.
When the program is run, it searches for an existing file to populate with its output. 
The touch command allows you to efficiently generate a blank text file to be used by such programs.

Most people use two-part names most of the time to help them (and their programs) tell different kinds of files apart. 
The second part of such a name is called the filename extension and indicates what type of data the file holds: 
.txt signals a plain text file, .pdf indicates a PDF document, .cfg is a configuration file full of parameters for some program or other, .png is a PNG image, and so on.

mv is used both to rename and also to actually move the file.

$ cut -d , -f 2 file.csv
The cut command is used to select or ‘cut out’ certain sections of each line in the file for further processing while leaving the original file unchanged.
By default, cut expects the lines to be separated into columns by a Tab character. A character used in this way is called a delimiter.
In the example above we use the -d option to specify the comma as our delimiter character instead of Tab. 
We have also used the -f option to specify that we want to extract the second field (column). 

Loops are a programming construct which allow us to repeat a command or set of commands for each item in a list. 
As such they are key to productivity improvements through automation. Similar to wildcards and tab completion, using loops also reduces the amount of typing required 
(and hence reduces the number of typing mistakes).

$ head -n 5 basilisk.dat minotaur.dat unicorn.dat
We would like to print out the classification for each species, which is given on the second line of each file. For each file, we would need to execute the command head -n 2 
and pipe this to tail -n 1. We’ll use a loop to solve this problem.

# The word "for" indicates the start of a "For-loop" command
for thing in list_of_things 
#The word "do" indicates the start of job execution list
do 
    # Indentation within the loop is not required, but aids legibility
    operation_using/command $thing 
# The word "done" indicates the end of a loop
done  
and we can apply this.

For example:

$ for filename in basilisk.dat minotaur.dat unicorn.dat
> do
>     echo $filename
>     head -n 2 $filename | tail -n 1
> done

Each time the loop runs (called an iteration), an item in the list is assigned in sequence to the variable, 
and the commands inside the loop are executed, before moving on to the next item in the list. 
Inside the loop, we call for the variable’s value by putting $ in front of it.
The $ tells the shell interpreter to treat the variable as a variable name and substitute its value in its place, rather than treat it as text or an external command.

We usually call programs like Microsoft Word or LibreOffice Writer “text editors”, but we need to be a bit more careful when it comes to programming. 
By default, Microsoft Word uses .docx files to store not only text, but also formatting information about fonts, headings, and so on.
This extra information isn’t stored as characters and doesn’t mean anything to tools like head, which expects input files to contain nothing but the letters, 
digits, and punctuation on a standard computer keyboard. When editing programs, therefore, you must either use a plain text editor or be careful to save files as plain text.

Now, within “nano”, replace the text octane.pdb with the special variable called $1:
head -n 15 "$1" | tail -n 5
Inside a shell script, $1 means ‘the first filename (or other argument) on the command line’. We can now run our script like this:
bash middle.sh octane.pdb

Currently, we need to edit middle.sh each time we want to adjust the range of lines that is returned. 
Let’s fix that by configuring our script to instead use three command-line arguments. 
After the first command-line argument ($1), each additional argument that we provide will be accessible via the special variables $1, $2, $3, 
which refer to the first, second, third command-line arguments, respectively.
Knowing this, we can use additional arguments to define the range of lines to be passed to head and tail respectively:
head -n "$2" "$1" | tail -n "$3"


$ wc -l *.pdb | sort -n
because wc -l lists the number of lines in the files (recall that wc stands for ‘word count’, adding the -l option means ‘count lines’ instead) 
and sort -n sorts things numerically. We could put this in a file, but then it would only ever sort a list of .pdb files in the current directory.
If we want to be able to get a sorted list of other kinds of files, we need a way to get all those names into the script. 
We can’t use $1, $2, and so on because we don’t know how many files there are. Instead, we use the special variable $@, which means, 
‘All of the command-line arguments to the shell script’. We also should put $@ inside double-quotes to handle the case of arguments 
containing spaces ("$@" is special syntax and is equivalent to "$1" "$2" …).

Here’s an example: nano sorted.sh

# Sort files by their length.
# Usage: bash sorted.sh one_or_more_filenames
wc -l "$@" | sort -n

We can use the command cut -d , -f 2 animals.csv | sort | uniq to produce the unique species in animals.csv. 
In order to avoid having to type out this series of commands every time, a scientist may choose to write a shell script instead.

Write a shell script called species.sh that takes any number of filenames as command-line arguments and uses a variation of the above command to
print a list of the unique species appearing in each of those files separately.

# Script to find unique species in csv files where species is the second data field
# This script accepts any number of file names as command line arguments

# Loop over all files
for file in $@
do
    echo "Unique species in $file:"
    # Extract species names
    cut -d , -f 2 $file | sort | uniq
done

